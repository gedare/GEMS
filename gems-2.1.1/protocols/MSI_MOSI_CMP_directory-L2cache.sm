
/*
    Copyright (C) 1999-2005 by Mark D. Hill and David A. Wood for the
    Wisconsin Multifacet Project.  Contact: gems@cs.wisc.edu
    http://www.cs.wisc.edu/gems/

    --------------------------------------------------------------------

    This file is part of the SLICC (Specification Language for
    Implementing Cache Coherence), a component of the Multifacet GEMS
    (General Execution-driven Multiprocessor Simulator) software
    toolset originally developed at the University of Wisconsin-Madison.
                                                                                
    SLICC was originally developed by Milo Martin with substantial
    contributions from Daniel Sorin.

    Substantial further development of Multifacet GEMS at the
    University of Wisconsin was performed by Alaa Alameldeen, Brad
    Beckmann, Jayaram Bobba, Ross Dickson, Dan Gibson, Pacia Harper,
    Derek Hower, Milo Martin, Michael Marty, Carl Mauer, Michelle Moravan,
    Kevin Moore, Manoj Plakal, Daniel Sorin, Haris Volos, Min Xu, and Luke Yen.

    --------------------------------------------------------------------

    If your use of this software contributes to a published paper, we
    request that you (1) cite our summary paper that appears on our
    website (http://www.cs.wisc.edu/gems/) and (2) e-mail a citation
    for your published paper to gems@cs.wisc.edu.

    If you redistribute derivatives of this software, we request that
    you notify us and either (1) ask people to register with us at our
    website (http://www.cs.wisc.edu/gems/) or (2) collect registration
    information and periodically send it to us.

    --------------------------------------------------------------------

    Multifacet GEMS is free software; you can redistribute it and/or
    modify it under the terms of version 2 of the GNU General Public
    License as published by the Free Software Foundation.

    Multifacet GEMS is distributed in the hope that it will be useful,
    but WITHOUT ANY WARRANTY; without even the implied warranty of
    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
    General Public License for more details.

    You should have received a copy of the GNU General Public License
    along with the Multifacet GEMS; if not, write to the Free Software
    Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA
    02111-1307, USA

    The GNU General Public License is contained in the file LICENSE.

### END HEADER ###
*/
/*
 * $Id$
 *
 */

machine(L2Cache, "MOSI Directory L2 Cache CMP") {

  // L2 BANK QUEUES
  // From local bank of L2 cache TO the network
  MessageBuffer dummyFrom0, network="To", virtual_network="0", ordered="false";  // dummy buffer that shouldn't be used
  MessageBuffer DirRequestFromL2Cache, network="To", virtual_network="1", ordered="false";  // this L2 bank -> mod-directory
  MessageBuffer L1RequestFromL2Cache, network="To", virtual_network="2", ordered="true";  // this L2 bank -> a local L1
  MessageBuffer responseFromL2Cache, network="To", virtual_network="3", ordered="false";  // this L2 bank -> a local L1 || mod-directory
  MessageBuffer finalAckFromL2Cache, network="To", virtual_network="4", ordered="false";  // this L2 bank -> mod-directory

  // FROM the network to this local bank of L2 cache
  //MessageBuffer L1RequestToL2Cache, network="From", virtual_network="1", ordered="true";  // a local L1 -> this L2 bank
  MessageBuffer L1RequestToL2Cache, network="From", virtual_network="0", ordered="true";  // a local L1 -> this L2 bank
  MessageBuffer dummyTo1, network="From", virtual_network="1", ordered="false";  // dummy buffer that shouldn't be used
  MessageBuffer forwardedRequestToL2Cache, network="From", virtual_network="2", ordered="true";  // mod-directory -> this L2 bank
  MessageBuffer responseToL2Cache, network="From", virtual_network="3", ordered="false";  // a local L1 || mod-directory -> this L2 bank
  MessageBuffer dummyTo4, network="From", virtual_network="4", ordered="false";  // dummy buffer that shouldn't be used

  // STATES
  enumeration(State, desc="L2 Cache states", default="L2Cache_State_L2_NP") {
    // Base states
    L2_NP, desc="Not present in either cache";
    L2_I, desc="L2 cache entry Idle";
    L2_S, desc="L2 cache entry Shared, not present in any local L1s";
    L2_O, desc="L2 cache entry Owned, not present in any local L1s";
    L2_M, desc="L2 cache entry Modified, not present in any L1s", format="!b";
    L2_SS, desc="L2 cache entry Shared, also present in one or more L1s";
    L2_SO, desc="L2 cache entry Owned, also present in one or more L1s or ext L2s";
    L2_MT, desc="L2 cache entry Modified in a local L1, assume L2 copy stale", format="!b";

    // Transient States

    // Transient States from I
    L2_IS, desc="L2 idle, issued GETS, have not seen response yet";
    L2_ISZ, desc="L2 idle, issued GETS, saw a L1_GETX, have not seen data for GETS yet", format="!b";
    L2_ISI, desc="L2 idle, issued GETS, saw INV, have not seen data for GETS yet", format="!b";
    L2_IMV, desc="L2 idle, issued GETX, valid int L1, have not seen response(s) yet";
    L2_MV, desc="L2 modified, a valid old L1 copy exist, external world gave write permission";
    L2_IM, desc="L2 idle, issued GETX, no valid int L1, have not seen response(s) yet";
    L2_IMO, desc="L2 idle, issued GETX, saw forwarded GETS";
    L2_IMI, desc="L2 idle, issued GETX, saw forwarded GETX";
    L2_IMZ, desc="L2 idle, issued GETX, saw another L1_GETX";
    L2_IMOI, desc="L2 idle, issued GETX, saw GETS, saw forwarded GETX";
    L2_IMOZ, desc="L2 idle, issued GETX, saw GETS, then a L1_GETX";

    // Invalidation steps for S -> I
    L2_SIC, desc="L2 shared, L2_INV, valid L1 copies exist, issued invalidates, have not seen responses yet";
    L2_SIV, desc="L2 shared, L2_Replacement, valid L1 copies exist, issued invalidates, have not seen responses yet";

    // Invalidation steps for M -> I for L2 Repalcement
    L2_MIV, desc="L2 modified, a valid L1 copy exist, issued forced writeback, have not seen the response yet";
    L2_MIN, desc="L2 modified, no valid L1 copies, issued PUTX, have not seen response yet";

    // Invalidation steps for M -> I for a Forwarded GetX
    L2_MIC, desc="L2 modified, a valid L1 copy exist, issued forced writeback, have not seen the response yet";

    // In MT state and see another L1_GETX request
    L2_MIT, desc="L2 modified, a valid L1 copy exist, saw L1_GETX, issued INV, have not seen the response yet";

    // Downgrade steps for M -> SO
    L2_MO, desc="L2 modified, a valid L1 copy exist, issued downgrade request, have not seen response yet";
    L2_MOIC, desc="L2 modified, a valid L1 copy exist, issued downgrade request, saw INV, have not seen response yet";
    L2_MOICR, desc="L2 modified, a valid L1 copy exist, issued invalidate request, saw INV, have not seen response yet";
    L2_MOZ, desc="L2 modified, a valid L1 copy exist, issued downgrade request, saw L1_GETX, have not seen response yet";

    // Invalidation steps for O/SO -> I for L2 Replacement
    L2_OIV, desc="L2 owned, valid L1 copies exist, issued invalidates, have not seen responses yet from L1s";
    L2_OIN, desc="L2 owned, no valid L1 copies, issued PUTX, have not seen response yet from dir";

    // Invalidation steps for SO -> I for a Forwarded GetX
    L2_OIC, desc="L2 owned, valid L1 copies exist, issued invalidates, have not seen responses yet from L1s";

    // Strange OM states
    // Note: strange states, because it is waiting for the line
    // to be stolen away, or look like it has been stolen away.  The
    // common case is that we see a forward from the directory that is
    // really from us, we forwarded the data to our dataqueue, and
    // everythings works fine.
    L2_OMV, desc="L2 owned and valid L1 copies, issued GETX and invalidates, have not seen responses yet";
    L2_OM, desc="L2 owned and no valid L1 copies, issued GETX, have not seen response yet";
  }

  // EVENTS
  enumeration(Event, desc="L2 Cache events") {
    // L2 events

    // events initiated by the local L1s
    L1_GET_INSTR,            desc="a L1I GET INSTR request for a block maped to us";
    L1_GETS,                 desc="a L1D GETS request for a block maped to us";
    L1_GETX,                 desc="a L1D GETX request for a block maped to us";
    L1_UPGRADE,              desc="a L1D UPGRADE request for a block maped to us";
    L1_UPGRADE_no_others,    desc="a L1D UPGRADE request for a block maped to us, requestor is the only on-chip sharer";
    L1_PUTX,                 desc="a L1D PUTX request for a block maped to us (L1 replacement of a modified block)";
    L1_PUTX_last,            desc="a L1D PUTX request for a block maped to us (L1 replacement of a modified block) last sharer";
    L1_PUTX_old,             desc="an old L1D PUTX request for a block maped to us (L1 replacement of a modified block)";
    L1_PUTS,                 desc="a L1 replacement of a shared block", format="!r";
    L1_PUTS_last,            desc="a L1 replacement of the last local L1 shared block", format="!r";
    L1_PUTS_old,             desc="an old L1 replacement of a shared block", format="!r";

    // events of local L1 responses
    Proc_int_ack, "Proc on-chip L1 Cache ack", desc="Ack from on-chip L1 Cache";
    Proc_last_int_ack, "Proc last on-chip L1 Cache ack", desc="Last on-chip L1 Cache ack", format="!r";

    Data_int_ack, "Data int ack",  desc="Received modified data from L1 now proceed in handling miss";
   
    // events initiated by the external L2s
    Forwarded_GETS, "Forwarded GETS", desc="Directory forwards Inter-chip GETS to us";
    Forwarded_GET_INSTR, "Forwarded GETINSTR", desc="Inter-chip Forwarded GETINSTR";
    Forwarded_GETX, "Forwarded GETX", desc="Directory forwards Inter-chip GETX to us";
    L2_INV, "L2_INV", desc="L2 Invalidation initiated from other L2", format="!r";

    // events initiated by this L2
    L2_Replacement,     desc="L2 Replacement", format="!r";

    // events of external L2 responses
    Proc_ext_ack, "Proc off-chip ack", desc="Ack from off-chip";
    Proc_last_ext_ack, "Proc last off-chip ack", desc="Last off-chip ack", format="!r";

    Data_ext_ack_0, "Data ack 0", desc="Data with ack count = 0";
    Data_ext_ack_not_0, "Data ack not 0", desc="Data with ack count != 0 (but haven't seen all acks first";
    // Data_ext_ack_not_0_last: is when the requestor has seen all acks but the directory has not, therefore
    // the directory must be told that we now have the data
    Data_ext_ack_not_0_last, "Data ack not 0 last", desc="Data with ack count != 0 after having received all acks";

    Dir_WB_ack, "WB ack", desc="Writeback ack from dir";
    Dir_exe_ack, "Only copy", desc="Directory tells us we already have exclusive permission, go directly to MT state";
  }

  // TYPES

  // CacheEntry
  structure(Entry, desc="...", interface="AbstractCacheEntry") {
    State CacheState,          desc="cache state";
    NetDest Sharers,               desc="tracks the L1 shares on-chip";
    DataBlock DataBlk,       desc="data for the block";
  }

  // TBE fields
  structure(TBE, desc="...") {
    Address Address,            desc="Physical address for this TBE";
    State TBEState,             desc="Transient state";
    DataBlock DataBlk,          desc="Buffer for the data block";
    int NumPendingExtAcks,      desc="Number of ext acks that this L2 bank is waiting for";
    int NumPendingIntAcks,      desc="Number of int acks that this L2 bank is waiting for";
    NetDest Forward_GetS_IDs,   desc="Set of the external processors to forward the block";
    NetDest L1_GetS_IDs,            desc="Set of the internal processors that want the block in shared state";
    MachineID Forward_GetX_ID,  desc="ID of the L2 cache to forward the block";
    MachineID L1_GetX_ID,          desc="ID of the L1 cache to forward the block to once we get a response";
    MachineID InvalidatorID,    desc="ID of the L2 cache (needed for L2_SS -> L2_I)";
    int ForwardGetX_AckCount,   desc="Number of acks the GetX we are forwarded needs";
    bool isPrefetch,            desc="Set if this was caused by a prefetch";
    bool isThreeHop,            desc="is this request a three hop";
    bool validForwardedGetXId,  desc="Indicate whether a forwarded GetX ID is valid";
    bool validInvalidator,      desc="Indicate whether an invalidator is valid";
    bool isInternalRequestOnly, desc="Is internal request only, i.e. only L1s";
  }

  external_type(CacheMemory) {
    bool cacheAvail(Address);
    Address cacheProbe(Address);
    void allocate(Address);
    void deallocate(Address);
    Entry lookup(Address);
    void changePermission(Address, AccessPermission);
    bool isTagPresent(Address);
    void setMRU(Address);
  }

  external_type(TBETable) {
    TBE lookup(Address);
    void allocate(Address);
    void deallocate(Address);
    bool isPresent(Address);
  }

  TBETable L2_TBEs, template_hack="<L2Cache_TBE>";

  CacheMemory L2cacheMemory, template_hack="<L2Cache_Entry>", constructor_hack='L2_CACHE_NUM_SETS_BITS,L2_CACHE_ASSOC,MachineType_L2Cache,int_to_string(i)';

  // inclusive cache, returns L2 entries only
  Entry getL2CacheEntry(Address addr), return_by_ref="yes" {
    return L2cacheMemory[addr];
  }

  void changeL2Permission(Address addr, AccessPermission permission) {
    if (L2cacheMemory.isTagPresent(addr)) {
      return L2cacheMemory.changePermission(addr, permission);
    }
  }

  string getCoherenceRequestTypeStr(CoherenceRequestType type) {
    return CoherenceRequestType_to_string(type);
  }

  bool isL2CacheTagPresent(Address addr) {
    return (L2cacheMemory.isTagPresent(addr));
  }

  bool isOneSharerLeft(Address addr, MachineID requestor) {
    assert(L2cacheMemory[addr].Sharers.isElement(requestor));
    return (L2cacheMemory[addr].Sharers.count() == 1);
  }

  bool isSharer(Address addr, MachineID requestor) {
    if (L2cacheMemory.isTagPresent(addr)) {
      return L2cacheMemory[addr].Sharers.isElement(requestor);
    } else {
      return false;
    }
  }

  void addSharer(Address addr, MachineID requestor) {
    DEBUG_EXPR(machineID);
    DEBUG_EXPR(requestor);
    DEBUG_EXPR(addr);
    assert(map_L1CacheMachId_to_L2Cache(addr, requestor) == machineID);
    L2cacheMemory[addr].Sharers.add(requestor);
  }

  State getState(Address addr) {
    if(L2_TBEs.isPresent(addr)) { 
      return L2_TBEs[addr].TBEState;
    } else if (isL2CacheTagPresent(addr)) {
      return getL2CacheEntry(addr).CacheState;
    }
    return State:L2_NP;
  }

  string getStateStr(Address addr) {
    return L2Cache_State_to_string(getState(addr));
  }

  // when is this called
  void setState(Address addr, State state) {

    // MUST CHANGE
    if (L2_TBEs.isPresent(addr)) {
      L2_TBEs[addr].TBEState := state;
    }

    if (isL2CacheTagPresent(addr)) {
      getL2CacheEntry(addr).CacheState := state;
    
      // Set permission  
      if (state == State:L2_I || 
          state == State:L2_SIC || state == State:L2_SIV || 
          state == State:L2_MIV || state == State:L2_MIN || state == State:L2_MIC || state == State:L2_MIT ||
          state == State:L2_OIV || state == State:L2_OIN || state == State:L2_OIC) {
        changeL2Permission(addr, AccessPermission:Invalid);
      } else if (state == State:L2_S || state == State:L2_O || state == State:L2_SS || state == State:L2_SO) {
        changeL2Permission(addr, AccessPermission:Read_Only);
      } else if (state == State:L2_OM || state == State:L2_OMV) {
        changeL2Permission(addr, AccessPermission:ReadUpgradingToWrite);
      } else if (state == State:L2_M) {
        changeL2Permission(addr, AccessPermission:Read_Write);
      } else if (state == State:L2_MT) {
        changeL2Permission(addr, AccessPermission:Stale);
      } else { 
        changeL2Permission(addr, AccessPermission:Busy);
      }
    }
  }

  Event L1Cache_request_type_to_event(CoherenceRequestType type, Address addr, MachineID requestor) {
    if(type == CoherenceRequestType:GETS) {
      return Event:L1_GETS;
    } else if(type == CoherenceRequestType:GET_INSTR) {
      return Event:L1_GET_INSTR;
    } else if (type == CoherenceRequestType:GETX) {
      return Event:L1_GETX;
    } else if (type == CoherenceRequestType:UPGRADE) {
      if (isSharer(addr, requestor)) {
        if (isOneSharerLeft(addr, requestor)) {
          return Event:L1_UPGRADE_no_others;
        } else {
          return Event:L1_UPGRADE;
        }
      } else {  // possible that we removed the line from the L2 before we could process the UPGRADE request
        return Event:L1_GETX;
      }
    } else if (type == CoherenceRequestType:PUTX) {
      if (isSharer(addr, requestor)) {
        if (isOneSharerLeft(addr, requestor)) {
          return Event:L1_PUTX_last;
        } else {
          return Event:L1_PUTX;
        }
      } else {
        return Event:L1_PUTX_old;
      }
    } else if (type == CoherenceRequestType:PUTS) {
      if (isSharer(addr, requestor)) {
        if (isOneSharerLeft(addr, requestor)) {
          return Event:L1_PUTS_last;
        } else {
          return Event:L1_PUTS;
        }
      } else {  // possible that we removed the line from the L2 before we could process the L1_PUTS request
        return Event:L1_PUTS_old;
      }
    } else {
      DEBUG_EXPR(addr);
      DEBUG_EXPR(type);
      error("Invalid L1 forwarded request type");
    }
  }

  // ** OUT_PORTS **
  // All ports output to the same CMP network, NI determines where to route msg

  out_port(L1RequestIntraChipL2Network_out, RequestMsg, L1RequestFromL2Cache);
  out_port(DirRequestIntraChipL2Network_out, RequestMsg, DirRequestFromL2Cache);
  out_port(responseIntraChipL2Network_out, ResponseMsg, responseFromL2Cache);
  out_port(finalAckIntraChipL2Network_out, ResponseMsg, finalAckFromL2Cache);

  // ** IN_PORTS **

  in_port(dummyTo1_in, RequestMsg, dummyTo1) {
    if (dummyTo1_in.isReady()) {
      peek(dummyTo1_in, RequestMsg) {
        DEBUG_EXPR(in_msg.Address);
        DEBUG_EXPR(id);
        DEBUG_EXPR(in_msg.Type);
        DEBUG_EXPR(getState(in_msg.Address));
        DEBUG_EXPR(in_msg.RequestorMachId);
      }
      error("dummyTo1 port should not be used");
    }
  }

  in_port(dummyTo4_in, ResponseMsg, dummyTo4) {
    if (dummyTo4_in.isReady()) {
      peek(dummyTo4_in, ResponseMsg) {
        DEBUG_EXPR(in_msg.Address);
        DEBUG_EXPR(id);
        DEBUG_EXPR(in_msg.Type);
        DEBUG_EXPR(getState(in_msg.Address));
        DEBUG_EXPR(in_msg.SenderMachId);
      }
      error("dummyTo4 port should not be used");
    }
  }

  // Response IntraChip L2 Network - response msg to this particular L2 bank
  in_port(responseIntraChipL2Network_in, ResponseMsg, responseToL2Cache) {
    if (responseIntraChipL2Network_in.isReady()) {
      peek(responseIntraChipL2Network_in, ResponseMsg) {
        DEBUG_EXPR(in_msg.Address);
        DEBUG_EXPR(id);
        DEBUG_EXPR(getState(in_msg.Address));
        DEBUG_EXPR(in_msg.SenderMachId);
        DEBUG_EXPR(in_msg.Type);
        DEBUG_EXPR(in_msg.NumPendingExtAcks);
        // test wether it's from a local L1 or an off chip source
        assert(in_msg.Destination.isElement(machineID));
        if(machineIDToMachineType(in_msg.SenderMachId) == MachineType:L1Cache) {
          if(in_msg.Type == CoherenceResponseType:DATA) {
            if(L2_TBEs[in_msg.Address].NumPendingIntAcks == 1) {
              trigger(Event:Data_int_ack, in_msg.Address);  // L1 now has data and all on-chip acks
            } else {
              DEBUG_EXPR(in_msg.Address);
              DEBUG_EXPR(L2_TBEs[in_msg.Address].NumPendingIntAcks);
              error("Invalid L1 sent data when L2 wasn't expecting it");
            }
          } else if(in_msg.Type == CoherenceResponseType:INV_ACK) {
            if(L2_TBEs.isPresent(in_msg.Address)) {  // FIXME - possible to get a L1 ack after the transaction is completed 
              if(L2_TBEs[in_msg.Address].NumPendingIntAcks == 1) {
                trigger(Event:Proc_last_int_ack, in_msg.Address);  // L1 now has all on-chip acks
              } else {
                trigger(Event:Proc_int_ack, in_msg.Address);  // process on-chip ack
              }
            }
          }
        } else { // external message
          if(in_msg.Type == CoherenceResponseType:DATA) {
            if(in_msg.NumPendingExtAcks == 0) {
              trigger(Event:Data_ext_ack_0, in_msg.Address);  // L2 now has data and all off-chip acks
            } else {
              if(in_msg.NumPendingExtAcks + L2_TBEs[in_msg.Address].NumPendingExtAcks != 0) {
                trigger(Event:Data_ext_ack_not_0, in_msg.Address);
              } else {
                trigger(Event:Data_ext_ack_not_0_last, in_msg.Address);
              }
            }
          } else if(in_msg.Type == CoherenceResponseType:ACK) {
            if(L2_TBEs[in_msg.Address].NumPendingExtAcks != 1){
              trigger(Event:Proc_ext_ack, in_msg.Address);
            } else {
              trigger(Event:Proc_last_ext_ack, in_msg.Address);
            }
          }
        }
      }
    }  // if not ready, do nothing
  }

  // Forwarded Request from Directory
  in_port(forwardedRequestIntraChipL2Network_in, RequestMsg, forwardedRequestToL2Cache) {
    if(forwardedRequestIntraChipL2Network_in.isReady()) {
      peek(forwardedRequestIntraChipL2Network_in, RequestMsg) {
        DEBUG_EXPR(in_msg.Address);
        DEBUG_EXPR(id);
        DEBUG_EXPR(getState(in_msg.Address));
        DEBUG_EXPR(in_msg.RequestorMachId);
        DEBUG_EXPR(in_msg.Type);
        assert(in_msg.Destination.isElement(machineID));
        if(in_msg.Type == CoherenceRequestType:GETS) {
          trigger(Event:Forwarded_GETS, in_msg.Address);  // L2
        } else if(in_msg.Type == CoherenceRequestType:GET_INSTR) {
          trigger(Event:Forwarded_GET_INSTR, in_msg.Address);  // L2
        } else if (in_msg.Type == CoherenceRequestType:GETX) {
          trigger(Event:Forwarded_GETX, in_msg.Address);  // L2
        } else if (in_msg.Type == CoherenceRequestType:INV) {
          trigger(Event:L2_INV, in_msg.Address);  // L2
        } else if (in_msg.Type == CoherenceRequestType:WB_ACK) {
          trigger(Event:Dir_WB_ack, in_msg.Address);  // L2
        } else if (in_msg.Type == CoherenceRequestType:EXE_ACK) {
          trigger(Event:Dir_exe_ack, in_msg.Address);  // L2
        } else {
          error("Invalid L2 forwarded request type");
        }
      }
    }
  }

  // L1 Request
  in_port(L1RequestIntraChipL2Network_in, RequestMsg, L1RequestToL2Cache) {
    if(L1RequestIntraChipL2Network_in.isReady()) {
      peek(L1RequestIntraChipL2Network_in,  RequestMsg) {
        DEBUG_EXPR(in_msg.Address);
        DEBUG_EXPR(id);
        DEBUG_EXPR(version);
        DEBUG_EXPR(getState(in_msg.Address));
        DEBUG_EXPR(in_msg.RequestorMachId);
        DEBUG_EXPR(in_msg.Type);
        DEBUG_EXPR(in_msg.Destination);
        assert(machineIDToMachineType(in_msg.RequestorMachId) == MachineType:L1Cache);
        assert(in_msg.Destination.isElement(machineID));
        if (L2cacheMemory.isTagPresent(in_msg.Address)) { 
          // The L2 contains the block, so proceeded with handling the request
          trigger(L1Cache_request_type_to_event(in_msg.Type, in_msg.Address, in_msg.RequestorMachId), in_msg.Address);
        } else {
          if (L2cacheMemory.cacheAvail(in_msg.Address)) {
            // L2 does't have the line, but we have space for it in the L2
            trigger(L1Cache_request_type_to_event(in_msg.Type, in_msg.Address, in_msg.RequestorMachId), in_msg.Address);
          } else {
            // No room in the L2, so we need to make room before handling the request
            trigger(Event:L2_Replacement, L2cacheMemory.cacheProbe(in_msg.Address));
          }
        }
      }
    }
  }

  // ACTIONS

  action(a_issueGETS, "a", desc="Issue GETS") {
    peek(L1RequestIntraChipL2Network_in, RequestMsg) {
      enqueue(DirRequestIntraChipL2Network_out, RequestMsg, latency="L2_REQUEST_LATENCY") {
        out_msg.Address := address;
        out_msg.Type := CoherenceRequestType:GETS;
        out_msg.RequestorMachId := machineID;
        out_msg.Destination.add(map_Address_to_Directory(address));
        out_msg.MessageSize := MessageSizeType:Control;
        out_msg.L1CacheStateStr := in_msg.L1CacheStateStr;
        out_msg.L2CacheStateStr := getStateStr(address);
      }
    }
  }

  action(b_issueGETX, "b", desc="Issue GETX") {
    peek(L1RequestIntraChipL2Network_in, RequestMsg) {
      enqueue(DirRequestIntraChipL2Network_out, RequestMsg, latency="L2_REQUEST_LATENCY") {
        out_msg.Address := address;
        out_msg.Type := CoherenceRequestType:GETX;
        out_msg.RequestorMachId := machineID;
        out_msg.Destination.add(map_Address_to_Directory(address));
        out_msg.MessageSize := MessageSizeType:Control;
        out_msg.L1CacheStateStr := in_msg.L1CacheStateStr;
        out_msg.L2CacheStateStr := getStateStr(address);
      }
    }
  }

  // finalAck issued from the response queue
  action(c_finalAckToDirIfNeeded, "c", desc="Send FinalAck to dir if this is response to 3-hop xfer") {
    peek(responseIntraChipL2Network_in, ResponseMsg) {
      DEBUG_EXPR(in_msg);
      if(machineIDToMachineType(in_msg.SenderMachId) == MachineType:L2Cache) {
        enqueue(finalAckIntraChipL2Network_out, ResponseMsg, latency="L2_RESPONSE_LATENCY"){
          out_msg.Address := address;
          out_msg.Type := CoherenceResponseType:FINALACK;
          out_msg.SenderMachId := machineID;
          out_msg.Destination.add(map_Address_to_Directory(address));
          out_msg.MessageSize := MessageSizeType:Control;
          DEBUG_EXPR(out_msg);
        }
      }
    }
  }

  // finalAck issued from TBE
  action(n_sendFinalAckIfThreeHop, "n", desc=""){
    peek(responseIntraChipL2Network_in, ResponseMsg){
      DEBUG_EXPR(in_msg);
      if(L2_TBEs[address].isThreeHop == true){
        enqueue(finalAckIntraChipL2Network_out, ResponseMsg, latency="L2_RESPONSE_LATENCY"){
          out_msg.Address := address;
          out_msg.Type := CoherenceResponseType:FINALACK;
          out_msg.SenderMachId := machineID;
          out_msg.Destination.add(map_Address_to_Directory(address));
          out_msg.MessageSize := MessageSizeType:Control;
          DEBUG_EXPR(out_msg);
        }
      }
    }
  }

  action(mm_rememberIfFinalAckNeeded, "\m", desc=""){
    peek(responseIntraChipL2Network_in, ResponseMsg){
      if(machineIDToMachineType(in_msg.SenderMachId) == MachineType:L2Cache){
        L2_TBEs[address].isThreeHop := true;
      }
    }
  }

  action(d_issuePUTX, "d", desc="Issue PUTX") {
    enqueue(DirRequestIntraChipL2Network_out, RequestMsg, latency="L2_REQUEST_LATENCY") {
      out_msg.Address := address;
      out_msg.Type := CoherenceRequestType:PUTX;
      out_msg.RequestorMachId := machineID;
      out_msg.Destination.add(map_Address_to_Directory(address));
      out_msg.DataBlk := getL2CacheEntry(address).DataBlk;
      DEBUG_EXPR(out_msg.Address);
      DEBUG_EXPR(out_msg.Destination);
      DEBUG_EXPR(out_msg.DataBlk);
      out_msg.MessageSize := MessageSizeType:Data;
      out_msg.L1CacheStateStr := "NA";
      out_msg.L2CacheStateStr := getStateStr(address);
    }
  }

  action(f_issueGETINSTR, "f", desc="Issue GETINSTR") {
    peek(L1RequestIntraChipL2Network_in, RequestMsg) {
      enqueue(DirRequestIntraChipL2Network_out, RequestMsg, latency="L2_REQUEST_LATENCY") {
        out_msg.Address := address;
        out_msg.Type := CoherenceRequestType:GET_INSTR;
        out_msg.RequestorMachId := machineID;
        out_msg.Destination.add(map_Address_to_Directory(address));
        out_msg.MessageSize := MessageSizeType:Control;
        out_msg.L1CacheStateStr := in_msg.L1CacheStateStr;
        out_msg.L2CacheStateStr := getStateStr(address);
      }
    }
  }

  // DELAYED RESPONSES - Sorced from a TBE entry
  // TBE -> L1
  action(h_issueLoadHit, "h", desc="If not prefetch, notify sequencer the load completed.") {
    DEBUG_EXPR(getL2CacheEntry(address).DataBlk);
    if((L2_TBEs.isPresent(address) == false) || (L2_TBEs[address].isPrefetch == false)) {
      // Non-prefetch
      enqueue(responseIntraChipL2Network_out, ResponseMsg, latency="L2_RESPONSE_LATENCY") {
        out_msg.Address := address;
        out_msg.Type := CoherenceResponseType:DATA;
        out_msg.SenderMachId := machineID;
        out_msg.Destination := L2_TBEs[address].L1_GetS_IDs;  // could be multiple internal nodes
        DEBUG_EXPR(out_msg.Destination);
        out_msg.DataBlk := getL2CacheEntry(address).DataBlk;
        out_msg.MessageSize := MessageSizeType:Data;
      }
    } else {
      // Prefetch - don't issue hit msg
    }
  }

  action(oo_issueLoadHitInv, "\o", desc="If not prefetch, notify sequencer the load completed.") {
    DEBUG_EXPR(getL2CacheEntry(address).DataBlk);
    if((L2_TBEs.isPresent(address) == false) || (L2_TBEs[address].isPrefetch == false)) {
      // Non-prefetch
      enqueue(responseIntraChipL2Network_out, ResponseMsg, latency="L2_RESPONSE_LATENCY") {
        out_msg.Address := address;
        out_msg.Type := CoherenceResponseType:DATA_I;
        out_msg.SenderMachId := machineID;
        out_msg.Destination := L2_TBEs[address].L1_GetS_IDs;  // could be multiple internal nodes
        DEBUG_EXPR(out_msg.Destination);
        out_msg.DataBlk := getL2CacheEntry(address).DataBlk;
        out_msg.MessageSize := MessageSizeType:Data;
      }
    } else {
      // Prefetch - don't issue hit msg
    }

  }

  action(hh_issueStoreHit, "\h", desc="If not prefetch, issue store hit message to local L1 requestor") {
    DEBUG_EXPR(getL2CacheEntry(address).DataBlk);
    if((L2_TBEs.isPresent(address) == false) || (L2_TBEs[address].isPrefetch == false)) {
      // Non-prefetch
      enqueue(responseIntraChipL2Network_out, ResponseMsg, latency="L2_RESPONSE_LATENCY") {
        out_msg.Address := address;
        out_msg.Type := CoherenceResponseType:DATA;
        out_msg.SenderMachId := machineID;
        out_msg.Destination.add(L2_TBEs[address].L1_GetX_ID);  // a single node
        DEBUG_EXPR(out_msg.Destination);
        out_msg.DataBlk := getL2CacheEntry(address).DataBlk;
        out_msg.MessageSize := MessageSizeType:Data;
      }
    } else {
      // Prefetch - don't issue hit msg
    }
  }

  action(pp_issueStoreHitInv, "\p", desc="If not prefetch, issue store hit message to local L1 requestor") {
    DEBUG_EXPR(getL2CacheEntry(address).DataBlk);
    if((L2_TBEs.isPresent(address) == false) || (L2_TBEs[address].isPrefetch == false)) {
      // Non-prefetch
      enqueue(responseIntraChipL2Network_out, ResponseMsg, latency="L2_RESPONSE_LATENCY") {
        out_msg.Address := address;
        out_msg.Type := CoherenceResponseType:DATA_I;
        out_msg.SenderMachId := machineID;
        out_msg.Destination.add(L2_TBEs[address].L1_GetX_ID);  // a single node
        DEBUG_EXPR(out_msg.Destination);
        out_msg.DataBlk := getL2CacheEntry(address).DataBlk;
        out_msg.MessageSize := MessageSizeType:Data;
      }
    } else {
      // Prefetch - don't issue hit msg
    }
  }

  action(cc_issueStoreHitDG, "\c", desc="If not prefetch, issue store hit message to local L1 requestor") {
    DEBUG_EXPR(getL2CacheEntry(address).DataBlk);
    if((L2_TBEs.isPresent(address) == false) || (L2_TBEs[address].isPrefetch == false)) {
      // Non-prefetch
      enqueue(responseIntraChipL2Network_out, ResponseMsg, latency="L2_RESPONSE_LATENCY") {
        out_msg.Address := address;
        out_msg.Type := CoherenceResponseType:DATA_S;
        out_msg.SenderMachId := machineID;
        out_msg.Destination.add(L2_TBEs[address].L1_GetX_ID);  // a single node
        DEBUG_EXPR(out_msg.Destination);
        out_msg.DataBlk := getL2CacheEntry(address).DataBlk;
        out_msg.MessageSize := MessageSizeType:Data;
      }
    } else {
      // Prefetch - don't issue hit msg
    }
  }

  action(w_sendPutAckToL1Cache, "w", desc="send acknowledgement of an L1 replacement") {
    peek(L1RequestIntraChipL2Network_in, RequestMsg) {
      enqueue(responseIntraChipL2Network_out, ResponseMsg, latency="L2_RESPONSE_LATENCY") {
        out_msg.Address := address;
        out_msg.Type := CoherenceResponseType:ACK;
        out_msg.SenderMachId := machineID;
        out_msg.Destination.add(in_msg.RequestorMachId);  // a single node
        DEBUG_EXPR(out_msg.Destination);
        out_msg.MessageSize := MessageSizeType:Control;
      }
    }
  }

  // TBE -> L1s and L2s
  action(ee_dataFromL2CacheToGetSIDs, "\e", desc="Send data from cache to all GetS IDs") {
    // FIXME - In some cases this should be from the TBE, not the cache.
    // may send to other mod-L2s
    if (L2_TBEs[address].Forward_GetS_IDs.count() > 0) {
      enqueue(responseIntraChipL2Network_out, ResponseMsg, latency="L2_RESPONSE_LATENCY") {
        out_msg.Address := address;
        out_msg.Type := CoherenceResponseType:DATA;
        out_msg.SenderMachId := machineID;
        out_msg.Destination := L2_TBEs[address].Forward_GetS_IDs;  // external nodes
        DEBUG_EXPR(out_msg.Destination);
        out_msg.DataBlk := getL2CacheEntry(address).DataBlk;
        out_msg.NumPendingExtAcks := 0;
        DEBUG_EXPR(out_msg.Address);
        DEBUG_EXPR(out_msg.Destination);
        DEBUG_EXPR(out_msg.DataBlk);
        out_msg.MessageSize := MessageSizeType:Data;
      }
    }
    // may send to local L1s
    if (L2_TBEs[address].L1_GetS_IDs.count() > 0) {
      enqueue(responseIntraChipL2Network_out, ResponseMsg, latency="L2_RESPONSE_LATENCY") {
        out_msg.Address := address;
        out_msg.Type := CoherenceResponseType:DATA;
        out_msg.SenderMachId := machineID;
        out_msg.Destination := L2_TBEs[address].L1_GetS_IDs;  // internal nodes
        DEBUG_EXPR(out_msg.Destination);
        out_msg.DataBlk := getL2CacheEntry(address).DataBlk;
        out_msg.MessageSize := MessageSizeType:Data;
      }
    }
  }

  // TBE -> L2s only
  action(bb_dataFromL2CacheToGetSForwardIDs, "\b", desc="Send data from cache to GetS ForwardIDs") {
    // FIXME - In some cases this should be from the TBE, not the cache.
    if ((L2_TBEs[address].Forward_GetS_IDs.count() > 0) || (L2_TBEs[address].L1_GetS_IDs.count() > 0)) {
      enqueue(responseIntraChipL2Network_out, ResponseMsg, latency="L2_RESPONSE_LATENCY") {
        out_msg.Address := address;
        out_msg.Type := CoherenceResponseType:DATA;
        out_msg.SenderMachId := machineID;
        out_msg.Destination := L2_TBEs[address].Forward_GetS_IDs;  // external nodes
        DEBUG_EXPR(out_msg.Destination);
        out_msg.DataBlk := getL2CacheEntry(address).DataBlk;
        out_msg.NumPendingExtAcks := 0;
        out_msg.MessageSize := MessageSizeType:Data;
      }
    }
  }

  // TBE -> L2 only
  action(gg_dataFromL2CacheToGetXForwardID, "\g", desc="Send data from cache to GetX ForwardID") {
    // FIXME - In some cases this should be from the TBE, not the cache.
    if (L2_TBEs[address].validForwardedGetXId) {
      enqueue(responseIntraChipL2Network_out, ResponseMsg, latency="L2_RESPONSE_LATENCY") {
        out_msg.Address := address;
        out_msg.Type := CoherenceResponseType:DATA;
        out_msg.SenderMachId := machineID;
        out_msg.Destination.add(L2_TBEs[address].Forward_GetX_ID);
        out_msg.DataBlk := getL2CacheEntry(address).DataBlk;
        out_msg.NumPendingExtAcks := L2_TBEs[address].ForwardGetX_AckCount;
        DEBUG_EXPR(out_msg.Address);
        DEBUG_EXPR(out_msg.Destination);
        DEBUG_EXPR(out_msg.DataBlk);
        DEBUG_EXPR(out_msg.NumPendingExtAcks);
        out_msg.MessageSize := MessageSizeType:Data;
      }
    }
  }

  // IMMEDIATE RESPONSES directly from the ForwardRequest queue
  // ForwardRequest -> L2
  action(e_dataFromL2CacheToL2Requestor, "e", desc="Send data from cache to requestor") {
    peek(forwardedRequestIntraChipL2Network_in, RequestMsg) {
      enqueue(responseIntraChipL2Network_out, ResponseMsg, latency="L2_RESPONSE_LATENCY") {
        out_msg.Address := address;
        out_msg.Type := CoherenceResponseType:DATA;
        out_msg.SenderMachId := machineID;
        out_msg.NumPendingExtAcks := in_msg.NumPendingExtAcks; // Needed when in state O and we see a GetX
        out_msg.Destination.add(in_msg.RequestorMachId);
        out_msg.DataBlk := getL2CacheEntry(address).DataBlk;
        DEBUG_EXPR(out_msg.Address);
        DEBUG_EXPR(out_msg.Destination);
        DEBUG_EXPR(out_msg.DataBlk);
        DEBUG_EXPR(out_msg.NumPendingExtAcks);
        out_msg.MessageSize := MessageSizeType:Data;
      }
    }
  }

  // ForwardRequest -> L1
  action(k_dataFromL2CacheToL1Requestor, "k", desc="Send data from cache to L1 requestor") {
    peek(L1RequestIntraChipL2Network_in, RequestMsg) {
      enqueue(responseIntraChipL2Network_out, ResponseMsg, latency="L2_RESPONSE_LATENCY") {
        out_msg.Address := address;
        out_msg.Type := CoherenceResponseType:DATA;
        out_msg.SenderMachId := machineID;
        out_msg.Destination.add(in_msg.RequestorMachId);
        DEBUG_EXPR(out_msg.Destination);
        out_msg.DataBlk := getL2CacheEntry(address).DataBlk;
        out_msg.MessageSize := MessageSizeType:Data;
      }
    }
  }

  // OTHER ACTIONS
  action(i_allocateTBE, "i", desc="Allocate TBE for internal/external request(isPrefetch=0, number of invalidates=0)") {
    check_allocate(L2_TBEs);
    L2_TBEs.allocate(address);
    L2_TBEs[address].NumPendingIntAcks := 0;  // default value
    L2_TBEs[address].NumPendingExtAcks := 0;  // default value
    L2_TBEs[address].isPrefetch := false;
    L2_TBEs[address].isThreeHop := false;
    L2_TBEs[address].Forward_GetS_IDs.clear();
    L2_TBEs[address].L1_GetS_IDs.clear();
    L2_TBEs[address].validInvalidator := false;
    L2_TBEs[address].validForwardedGetXId := false;
    L2_TBEs[address].isInternalRequestOnly := false;
  }

  action(s_deallocateTBE, "s", desc="Deallocate external TBE") {
    L2_TBEs.deallocate(address);
  }

  action(jj_popL1RequestQueue, "\j", desc="Pop incoming L1 request queue") {
    profileMsgDelay(0, L1RequestIntraChipL2Network_in.dequeue_getDelayCycles());
  }

  action(l_popForwardedRequestQueue, "l", desc="Pop incoming forwarded request queue") {
    profileMsgDelay(2, forwardedRequestIntraChipL2Network_in.dequeue_getDelayCycles());
  }

  action(o_popIncomingResponseQueue, "o", desc="Pop Incoming Response queue") {
    profileMsgDelay(3, responseIntraChipL2Network_in.dequeue_getDelayCycles());
  }

  action(p_addNumberOfPendingExtAcks, "p", desc="Add number of pending acks to TBE") {
    peek(responseIntraChipL2Network_in, ResponseMsg) {
      DEBUG_EXPR(L2_TBEs[address].NumPendingExtAcks);
      L2_TBEs[address].NumPendingExtAcks := L2_TBEs[address].NumPendingExtAcks + in_msg.NumPendingExtAcks;
      DEBUG_EXPR(in_msg.NumPendingExtAcks);
      DEBUG_EXPR(L2_TBEs[address].NumPendingExtAcks);
    }
  }

  action(q_decrementNumberOfPendingExtAcks, "q", desc="Decrement number of pending ext invalidations by one") {
    DEBUG_EXPR(L2_TBEs[address].NumPendingExtAcks);
    L2_TBEs[address].NumPendingExtAcks := L2_TBEs[address].NumPendingExtAcks - 1;
    DEBUG_EXPR(L2_TBEs[address].NumPendingExtAcks);
  }

  action(r_decrementNumberOfPendingIntAcks, "r", desc="Decrement number of pending int invalidations by one") {
    DEBUG_EXPR(L2_TBEs[address].NumPendingExtAcks);
    L2_TBEs[address].NumPendingIntAcks := L2_TBEs[address].NumPendingIntAcks - 1;
    DEBUG_EXPR(L2_TBEs[address].NumPendingExtAcks);
  }

  action(t_sendAckToInvalidator, "t", desc="Send ack to invalidator") {
    peek(forwardedRequestIntraChipL2Network_in, RequestMsg) {
      enqueue(responseIntraChipL2Network_out, ResponseMsg, latency="L2_RESPONSE_LATENCY") {
        out_msg.Address := address;
        out_msg.Type := CoherenceResponseType:ACK;
        out_msg.SenderMachId := machineID;
        out_msg.Destination.add(in_msg.RequestorMachId);
        DEBUG_EXPR(out_msg.Destination);
        out_msg.NumPendingExtAcks := 0;       
        out_msg.MessageSize := MessageSizeType:Control;
      }
    }
  }
  
  action(u_writeDataFromResponseQueueToL2Cache, "u", desc="Write data from response queue to cache") {
    peek(responseIntraChipL2Network_in, ResponseMsg) {
      getL2CacheEntry(address).DataBlk := in_msg.DataBlk;
    }
  }
  
  // FIXME - probably need to change this to a seperate low priority request queue
  action(m_writeDataFromRequestQueueToL2Cache, "m", desc="Write data from response queue to cache") {
    peek(L1RequestIntraChipL2Network_in, RequestMsg) {
      getL2CacheEntry(address).DataBlk := in_msg.DataBlk;
    }
  }
  
  action(x_copyDataFromL2CacheToTBE, "x", desc="Copy data from cache to TBE") {
    L2_TBEs[address].DataBlk := getL2CacheEntry(address).DataBlk;
  }

  action(y_dataFromTBEToRequestor, "y", desc="Send data from TBE to requestor") {
    peek(forwardedRequestIntraChipL2Network_in, RequestMsg) {
      enqueue(responseIntraChipL2Network_out, ResponseMsg, latency="L2_RESPONSE_LATENCY") {
        out_msg.Address := address;
        out_msg.Type := CoherenceResponseType:DATA;
        out_msg.SenderMachId := machineID;
        out_msg.NumPendingExtAcks := in_msg.NumPendingExtAcks;
        out_msg.Destination.add(in_msg.RequestorMachId);
        out_msg.DataBlk := L2_TBEs[address].DataBlk;
        DEBUG_EXPR(out_msg.Address);
        DEBUG_EXPR(out_msg.Destination);
        DEBUG_EXPR(out_msg.DataBlk);
        DEBUG_EXPR(out_msg.NumPendingExtAcks);
        out_msg.MessageSize := MessageSizeType:Data;
      }
    }
  }
  
  action(zz_sendAckToQueuedInvalidator, "\z", desc="Send ack to invalidator") {
    if (L2_TBEs[address].validInvalidator) {
      enqueue(responseIntraChipL2Network_out, ResponseMsg, latency="L2_RESPONSE_LATENCY") {
        out_msg.Address := address;
        out_msg.Type := CoherenceResponseType:ACK;
        out_msg.SenderMachId := machineID;
        out_msg.Destination.add(L2_TBEs[address].InvalidatorID);
        DEBUG_EXPR(out_msg.Destination);
        out_msg.NumPendingExtAcks := 0;       
        out_msg.MessageSize := MessageSizeType:Control;
      }
    }
  }
  
  action(z_stall, "z", desc="Stall") {
  }
  
  action(yy_recordInvalidatorID, "\y", desc="Record Invalidator for future response") {
    peek(forwardedRequestIntraChipL2Network_in, RequestMsg) {
      L2_TBEs[address].InvalidatorID := in_msg.RequestorMachId;
      L2_TBEs[address].validInvalidator := true;
    }
  }

  action(dd_recordGetSForwardID, "\d", desc="Record forwarded GetS for future forwarding") {
    peek(forwardedRequestIntraChipL2Network_in, RequestMsg) {
      L2_TBEs[address].Forward_GetS_IDs.add(in_msg.RequestorMachId);
    }
  }

  action(ss_recordGetSL1ID, "\s", desc="Record forwarded L1 GetS for load response") {
    peek(L1RequestIntraChipL2Network_in, RequestMsg) {
      L2_TBEs[address].L1_GetS_IDs.add(in_msg.RequestorMachId);
    }
  }
  
  action(ii_recordGetXForwardID, "\i", desc="Record forwarded GetX and ack count for future forwarding") {
    peek(forwardedRequestIntraChipL2Network_in, RequestMsg) {
      L2_TBEs[address].Forward_GetX_ID := in_msg.RequestorMachId;
      L2_TBEs[address].ForwardGetX_AckCount := in_msg.NumPendingExtAcks;
      L2_TBEs[address].validForwardedGetXId := true;
    }
  }

  action(xx_recordGetXL1ID, "\x", desc="Record L1 GetX for store response") {
    peek(L1RequestIntraChipL2Network_in, RequestMsg) {
      L2_TBEs[address].L1_GetX_ID := in_msg.RequestorMachId;
    }
  }

  action(set_setMRU, "\set", desc="set the MRU entry") {
    L2cacheMemory.setMRU(address);
  }

  action(bbb_setPendingIntAcksToSharers, "\bb", desc="Set number of pending acks equal to number of sharers") {
    L2_TBEs[address].NumPendingIntAcks := L2cacheMemory[address].Sharers.count();
  }

  action(ddd_setPendingIntAcksToOne, "\dd", desc="Set number of pending acks equal to one") {
    L2_TBEs[address].NumPendingIntAcks := 1;
  }

  action(ccc_setPendingIntAcksMinusOne, "\cc", desc="Set number of pending acks equal to number of sharers minus one") {
    L2_TBEs[address].NumPendingIntAcks := L2cacheMemory[address].Sharers.count() - 1;
  }

  action(qq_allocateL2CacheBlock, "\q", desc="Set L2 cache tag equal to tag of block B.") {
    if (L2cacheMemory.isTagPresent(address) == false) {
      L2cacheMemory.allocate(address);
    }
  }

  action(rr_deallocateL2CacheBlock, "\r", desc="Deallocate L2 cache block.  Sets the cache to not present, allowing a replacement in parallel with a fetch.") {
    L2cacheMemory.deallocate(address);
  }

  action(uu_profileMiss, "\u", desc="Profile the demand miss") {
    peek(L1RequestIntraChipL2Network_in, RequestMsg) {
      profile_L2Cache_miss(convertToGenericType(in_msg.Type), in_msg.AccessMode, MessageSizeTypeToInt(in_msg.MessageSize), in_msg.Prefetch, L1CacheMachIDToProcessorNum(in_msg.RequestorMachId));
    }
  }

  action(ww_profileMissNoDir, "\w", desc="Profile this transition at the L2 because Dir won't see the request") {
    peek(L1RequestIntraChipL2Network_in, RequestMsg) {
      profile_request(in_msg.L1CacheStateStr, getStateStr(address), "NA", getCoherenceRequestTypeStr(in_msg.Type));
    }
  }

  action(v_issueInvalidateIntL1copyRequest, "v", desc="invalidate the L1 M copy") {
    enqueue(L1RequestIntraChipL2Network_out, RequestMsg, latency="L2_REQUEST_LATENCY") {
      out_msg.Address := address;
      out_msg.Type := CoherenceRequestType:INV;
      out_msg.RequestorMachId := machineID;
      out_msg.Destination := L2cacheMemory[address].Sharers;
      out_msg.MessageSize := MessageSizeType:Control;
    }
  }

  action(tt_issueSharedInvalidateIntL1copiesRequest, "\t", desc="invalidate all L1 S copies") {
    enqueue(L1RequestIntraChipL2Network_out, RequestMsg, latency="L2_REQUEST_LATENCY") {
      out_msg.Address := address;
      out_msg.Type := CoherenceRequestType:INV_S;
      out_msg.RequestorMachId := machineID;
      out_msg.Destination := L2cacheMemory[address].Sharers;
      out_msg.MessageSize := MessageSizeType:Control;
    }
  }

  action(vv_issueInvalidateOtherIntL1copiesRequest, "\v", desc="invalidate other L1 copies not the local requestor") {
    peek(L1RequestIntraChipL2Network_in, RequestMsg) {
      if ((L2cacheMemory[address].Sharers.count() > 1) || (L2cacheMemory[address].Sharers.isElement(in_msg.RequestorMachId) != true)) {
        enqueue(L1RequestIntraChipL2Network_out, RequestMsg, latency="L2_REQUEST_LATENCY") {
          out_msg.Address := address;
          out_msg.Type := CoherenceRequestType:INV_S;
          out_msg.RequestorMachId := machineID;
          out_msg.Destination := L2cacheMemory[address].Sharers;
          out_msg.Destination.remove(in_msg.RequestorMachId);
          out_msg.MessageSize := MessageSizeType:Control;
        }
      }
    }
  }

  action(g_issueDownGradeIntL1copiesRequest, "g", desc="DownGrade L1 copy") {
    enqueue(L1RequestIntraChipL2Network_out, RequestMsg, latency="L2_REQUEST_LATENCY") {
      out_msg.Address := address;
      out_msg.Type := CoherenceRequestType:L1_DG;
      out_msg.RequestorMachId := machineID;
      out_msg.Destination := L2cacheMemory[address].Sharers;
      out_msg.MessageSize := MessageSizeType:Control;
    }
  }

  action(nn_addSharer, "\n", desc="Add L1 sharer to list") {
    peek(L1RequestIntraChipL2Network_in, RequestMsg) {
      addSharer(address, in_msg.RequestorMachId);
    }    
  }

  action(kk_removeRequestSharer, "\k", desc="Remove L1 Request sharer from list") {
    peek(L1RequestIntraChipL2Network_in, RequestMsg) {
      L2cacheMemory[address].Sharers.remove(in_msg.RequestorMachId);
    }    
  }

  action(aa_removeResponseSharer, "\a", desc="Remove L1 Response sharer from list") {
    peek(responseIntraChipL2Network_in, ResponseMsg) {
      L2cacheMemory[address].Sharers.remove(in_msg.SenderMachId);
    }    
  }

  action(ll_clearSharers, "\l", desc="Remove all L1 sharers from list") {
    peek(L1RequestIntraChipL2Network_in, RequestMsg) {
      L2cacheMemory[address].Sharers.clear();
    }    
  }

  //*****************************************************
  // TRANSITIONS
  //*****************************************************

  //===============================================
  // STALLS

  // Stalls L2 Replacement and L1 PUT for all transient states
  transition({L2_IS, L2_ISZ, L2_ISI, L2_IMV, L2_MV, L2_IM, L2_IMO, L2_IMI, L2_IMZ, L2_IMOI, L2_IMOZ, 
                L2_SIV, L2_SIC, 
                L2_MIV, L2_MIN, L2_MIC, L2_MIT, L2_MO, L2_MOIC, L2_MOICR, L2_MOZ, 
                L2_OIV, L2_OIN, L2_OIC, L2_OMV, L2_OM}, 
  {L2_Replacement, L1_PUTX, L1_PUTX_last, L1_PUTS, L1_PUTS_last, L1_PUTX_old, L1_PUTS_old, }) {
    z_stall;
  }

  //===============================================
  // old L1_PUT requests

  transition({L2_NP, L2_I, L2_S, L2_SS, L2_M, L2_MT, L2_O, L2_SO}, {L1_PUTX_old, L1_PUTS_old}) {
    w_sendPutAckToL1Cache;
    jj_popL1RequestQueue;
  }

  //===============================================
  // BASE STATE - I

  // Transitions from I (Idle)
  transition({L2_NP,L2_I}, L2_Replacement) {
    rr_deallocateL2CacheBlock;
  }

  transition({L2_NP,L2_I}, L2_INV) {  // could see an invalidate from the directory, but not Forwards
    t_sendAckToInvalidator;
    l_popForwardedRequestQueue;
  }

  transition({L2_NP,L2_I}, L1_GETS, L2_IS) {
    qq_allocateL2CacheBlock;
    ll_clearSharers;
    nn_addSharer;
    i_allocateTBE;
    ss_recordGetSL1ID;
    a_issueGETS;
    uu_profileMiss;
    jj_popL1RequestQueue;
  }

  transition({L2_NP,L2_I}, L1_GET_INSTR, L2_IS) {
    qq_allocateL2CacheBlock;
    ll_clearSharers;
    nn_addSharer;
    i_allocateTBE;
    ss_recordGetSL1ID;
    f_issueGETINSTR;
    uu_profileMiss;
    jj_popL1RequestQueue;
  }

  transition({L2_NP,L2_I}, {L1_GETX, L1_UPGRADE, L1_UPGRADE_no_others}, L2_IM) {  // UPGRADE possible because L2_Replacement have higher priority
    qq_allocateL2CacheBlock;
    ll_clearSharers;
    nn_addSharer;
    i_allocateTBE;
    xx_recordGetXL1ID;
    b_issueGETX;
    uu_profileMiss;
    jj_popL1RequestQueue;
  }

  // Transitions from L2_IS
  // could see L2_INVs or more L1 requests
  transition(L2_IS, L2_INV, L2_ISI) {  // could see an invalidate from the directory, but not Forwards
    t_sendAckToInvalidator;
    l_popForwardedRequestQueue;
  }

  transition(L2_IS, Data_ext_ack_0, L2_SS) {
    u_writeDataFromResponseQueueToL2Cache;
    h_issueLoadHit;
    c_finalAckToDirIfNeeded;
    s_deallocateTBE;
    o_popIncomingResponseQueue;
  }

  transition(L2_IS, {L1_GETS,L1_GET_INSTR}) {
    set_setMRU;
    ww_profileMissNoDir;
    nn_addSharer;
    ss_recordGetSL1ID;
    jj_popL1RequestQueue;
  }

  transition(L2_IS, L1_GETX, L2_ISZ) {  // don't go there, just go to stall state
    z_stall;
  }

  // Transitions from L2_ISZ
  // could see L2_INVs or more L1 requests
  // stall all L1 requests, wait for data
  transition(L2_ISZ, L2_INV, L2_ISI) {  // could see an invalidate from the directory, but not Forwards
    t_sendAckToInvalidator;
    l_popForwardedRequestQueue;
  }

  transition(L2_ISZ, Data_ext_ack_0, L2_SS) {
    u_writeDataFromResponseQueueToL2Cache;
    h_issueLoadHit;
    c_finalAckToDirIfNeeded;
    s_deallocateTBE;
    o_popIncomingResponseQueue;
  }

  transition(L2_ISZ, {L1_GETS, L1_GET_INSTR, L1_GETX}) {
    z_stall;
  }

  // Transitions from L2_ISI, already sent the invalidate ack so can imediately go to I
  // - in ISI, could get data from the Proc whose GETX caused INV to go from IS to ISI
  // or, could get data from Dir if Dir's data lost race to Dir's INV
  // or, could get data from Dir, if my GETS took forever to get to Dir, and the GETX
  // processor already wrote it back
  transition(L2_ISI, Data_ext_ack_0, L2_I) {
    u_writeDataFromResponseQueueToL2Cache;
    oo_issueLoadHitInv;
    c_finalAckToDirIfNeeded;
    s_deallocateTBE;
    o_popIncomingResponseQueue;
  }

  transition(L2_ISI, L2_INV) {  // could see an invalidate from the directory, but not Forwards
    t_sendAckToInvalidator;
    l_popForwardedRequestQueue;
  }

  transition(L2_ISI, {L1_GETS, L1_GET_INSTR, L1_GETX}) {  // stall all L1 requests
    z_stall;
  }

  // Transitions from L2_IMV, waiting for int_acks
  // currently stall all request 
  // could see forwards and/or more L1 requests
  transition(L2_IMV, L2_INV) {  // could see an invalidate for SS
    yy_recordInvalidatorID;
    l_popForwardedRequestQueue;
  }

  // stall all Forwarded request
  transition(L2_IMV, {Forwarded_GETS, Forwarded_GET_INSTR, Forwarded_GETX}) {
    z_stall;
  }

  // stall all L1 request
  transition(L2_IMV, {L1_GETS, L1_GET_INSTR, L1_GETX, L1_UPGRADE, L1_UPGRADE_no_others}) {
    z_stall;
  }  

  transition(L2_IMV, {Data_ext_ack_0, Data_ext_ack_not_0_last}, L2_MV) {
    u_writeDataFromResponseQueueToL2Cache;
    c_finalAckToDirIfNeeded;
    o_popIncomingResponseQueue;
  }

  transition(L2_IMV, Data_ext_ack_not_0) {
    u_writeDataFromResponseQueueToL2Cache;
    p_addNumberOfPendingExtAcks;
    mm_rememberIfFinalAckNeeded;
    o_popIncomingResponseQueue;
  }

  transition(L2_IMV, Proc_ext_ack) {
    q_decrementNumberOfPendingExtAcks;
    o_popIncomingResponseQueue;
  }

  transition(L2_IMV, Proc_last_ext_ack, L2_MV) {
    n_sendFinalAckIfThreeHop;
    o_popIncomingResponseQueue;
  }

  transition(L2_IMV, Proc_int_ack) {
    aa_removeResponseSharer;
    r_decrementNumberOfPendingIntAcks;
    o_popIncomingResponseQueue;
  }

  transition(L2_IMV, Proc_last_int_ack, L2_IM) {
    aa_removeResponseSharer;
    r_decrementNumberOfPendingIntAcks;
    o_popIncomingResponseQueue;
    zz_sendAckToQueuedInvalidator;
  }

  // Transitions from L2_MV, waiting for int_acks
  // external world gave us write permission

  // stall all Forwarded request
  transition(L2_MV, {Forwarded_GETS, Forwarded_GET_INSTR, Forwarded_GETX}) {
    z_stall;
  }

  // stall all L1 request
  transition(L2_MV, {L1_GETS, L1_GET_INSTR, L1_GETX, L1_UPGRADE, L1_UPGRADE_no_others}) {
    z_stall;
  }  

  transition(L2_MV, Proc_int_ack) {
    aa_removeResponseSharer;
    r_decrementNumberOfPendingIntAcks;
    o_popIncomingResponseQueue;
  }

  transition(L2_MV, Proc_last_int_ack, L2_MT) {
    aa_removeResponseSharer;
    r_decrementNumberOfPendingIntAcks;
    hh_issueStoreHit;
    s_deallocateTBE;
    o_popIncomingResponseQueue;
  }

  // Transitions from L2_IM, waiting for external data before going to MT state
  // could see forwards and/or more L1 requests
  transition(L2_IM, L2_INV) {  // could see an invalidate from the directory (earlier epoch)
    t_sendAckToInvalidator;
    l_popForwardedRequestQueue;
  }

  transition(L2_IM, {Forwarded_GETS,Forwarded_GET_INSTR}, L2_IMO) {  // could see Forwards, if directory responses get out-of-order
    dd_recordGetSForwardID;
    l_popForwardedRequestQueue;
  }

  transition(L2_IM, {L1_GETS,L1_GET_INSTR}, L2_IMO) {
    set_setMRU;
    ww_profileMissNoDir;
    nn_addSharer;
    ss_recordGetSL1ID;
    jj_popL1RequestQueue;
  }

  transition(L2_IM, Forwarded_GETX, L2_IMI) {  // could see Forwards, if directory requests get ahead of responses 
    ii_recordGetXForwardID;
    l_popForwardedRequestQueue;
  }

  transition(L2_IM, L1_GETX, L2_IMZ) {  // don't go there, just go to stall state
    z_stall;
  }  

  transition(L2_IM, {Data_ext_ack_0, Data_ext_ack_not_0_last}, L2_MT) {
    u_writeDataFromResponseQueueToL2Cache;
    hh_issueStoreHit;
    c_finalAckToDirIfNeeded;
    s_deallocateTBE;
    o_popIncomingResponseQueue;
  }

  transition(L2_IM, Data_ext_ack_not_0) {
    u_writeDataFromResponseQueueToL2Cache;
    p_addNumberOfPendingExtAcks;
    mm_rememberIfFinalAckNeeded;
    o_popIncomingResponseQueue;
  }

  transition(L2_IM, Proc_ext_ack) {
    q_decrementNumberOfPendingExtAcks;
    o_popIncomingResponseQueue;
  }

  transition(L2_IM, Proc_last_ext_ack, L2_MT) {
    hh_issueStoreHit;
    n_sendFinalAckIfThreeHop;
    s_deallocateTBE;
    o_popIncomingResponseQueue;
  }

  // transitions from L2_IMO
  transition(L2_IMO, L2_INV) {  // could see an invalidate from the directory (earlier epoch)
    t_sendAckToInvalidator;
    l_popForwardedRequestQueue;
  }

  transition(L2_IMO, {Forwarded_GETS,Forwarded_GET_INSTR}) {  // could see Forwards
    dd_recordGetSForwardID;
    l_popForwardedRequestQueue;
  }

  transition(L2_IMO, Forwarded_GETX, L2_IMOI) {  // could see Forwards
    ii_recordGetXForwardID;
    l_popForwardedRequestQueue;
  }

  transition(L2_IMO, {L1_GETS,L1_GET_INSTR}) {
    set_setMRU;
    ww_profileMissNoDir;
    nn_addSharer;
    ss_recordGetSL1ID;
    jj_popL1RequestQueue;
  }

  transition(L2_IMO, L1_GETX, L2_IMOZ) {
    z_stall;
  }

  transition(L2_IMO, {Data_ext_ack_0, Data_ext_ack_not_0_last}, L2_MO) {
    u_writeDataFromResponseQueueToL2Cache;
    cc_issueStoreHitDG;
    ddd_setPendingIntAcksToOne;
    c_finalAckToDirIfNeeded;  
    o_popIncomingResponseQueue;
  }

  transition(L2_IMO, Data_ext_ack_not_0) {
    u_writeDataFromResponseQueueToL2Cache;
    p_addNumberOfPendingExtAcks;
    mm_rememberIfFinalAckNeeded;
    o_popIncomingResponseQueue;
  }

  transition(L2_IMO, Proc_ext_ack) {
    q_decrementNumberOfPendingExtAcks;
    o_popIncomingResponseQueue;
  }

  transition(L2_IMO, Proc_last_ext_ack, L2_MO) {
    n_sendFinalAckIfThreeHop;
    cc_issueStoreHitDG;
    ddd_setPendingIntAcksToOne;
    o_popIncomingResponseQueue;
  }

  // transitions from L2_IMI
  // the directory put us in this state so it should tell us nothing (i.e. don't worry about INV or Forwards)
  // stall all L1 request
  transition(L2_IMI, {Data_ext_ack_0, Data_ext_ack_not_0_last}, L2_MIC) {
    u_writeDataFromResponseQueueToL2Cache;
    pp_issueStoreHitInv;
    ddd_setPendingIntAcksToOne;
    c_finalAckToDirIfNeeded;
    o_popIncomingResponseQueue;
  }

  transition(L2_IMI, Data_ext_ack_not_0) {
    u_writeDataFromResponseQueueToL2Cache;
    p_addNumberOfPendingExtAcks;
    mm_rememberIfFinalAckNeeded;
    o_popIncomingResponseQueue;
  }

  transition(L2_IMI, Proc_ext_ack) {
    q_decrementNumberOfPendingExtAcks;
    o_popIncomingResponseQueue;
  }

  transition(L2_IMI, Proc_last_ext_ack, L2_MIC) {
    n_sendFinalAckIfThreeHop;
    pp_issueStoreHitInv;
    ddd_setPendingIntAcksToOne;
    o_popIncomingResponseQueue;
  }

  transition(L2_IMI, {L1_GETS, L1_GET_INSTR, L1_GETX}) {  // stall all L1 requests
    z_stall;
  }

  // transistions from L2_IMZ
  // just wait for all acks and data
  // stall on all requests
  // NOTE: A performance option might be possible to go into M state instead of MT
  transition(L2_IMZ, {Data_ext_ack_0, Data_ext_ack_not_0_last}, L2_MT) {
    u_writeDataFromResponseQueueToL2Cache;
    hh_issueStoreHit;
    c_finalAckToDirIfNeeded;
    s_deallocateTBE;
    o_popIncomingResponseQueue;
  }

  transition(L2_IMZ, Data_ext_ack_not_0) {
    u_writeDataFromResponseQueueToL2Cache;
    p_addNumberOfPendingExtAcks;
    mm_rememberIfFinalAckNeeded;
    o_popIncomingResponseQueue;
  }

  transition(L2_IMZ, Proc_ext_ack) {
    q_decrementNumberOfPendingExtAcks;
    o_popIncomingResponseQueue;
  }

  transition(L2_IMZ, Proc_last_ext_ack, L2_MT) {
    hh_issueStoreHit;
    n_sendFinalAckIfThreeHop;
    s_deallocateTBE;
    o_popIncomingResponseQueue;
  }

  transition(L2_IMZ, L2_INV) {  // could see an invalidate from the directory (earlier epoch)
    t_sendAckToInvalidator;
    l_popForwardedRequestQueue;
  }

  transition(L2_IMZ, {Forwarded_GETS, Forwarded_GET_INSTR, Forwarded_GETX, L1_GETS, L1_GET_INSTR, L1_GETX}) {
    z_stall;
  }

  // transitions from L2_IMOI
  // the directory put us in this state so it should tell us nothing (i.e. don't worry about INV or Forwards)
  // stall all L1 requests
  transition(L2_IMOI, {Data_ext_ack_0, Data_ext_ack_not_0_last}, L2_MOICR) {
    u_writeDataFromResponseQueueToL2Cache;
    pp_issueStoreHitInv;
    ddd_setPendingIntAcksToOne;
    c_finalAckToDirIfNeeded;
    o_popIncomingResponseQueue;
  }

  transition(L2_IMOI, Data_ext_ack_not_0) {
    u_writeDataFromResponseQueueToL2Cache;
    p_addNumberOfPendingExtAcks;
    mm_rememberIfFinalAckNeeded;
    o_popIncomingResponseQueue;
  }

  transition(L2_IMOI, Proc_ext_ack) {
    q_decrementNumberOfPendingExtAcks;
    o_popIncomingResponseQueue;
  }

  transition(L2_IMOI, Proc_last_ext_ack, L2_MOICR) {
    n_sendFinalAckIfThreeHop;
    pp_issueStoreHitInv;
    ddd_setPendingIntAcksToOne;
    o_popIncomingResponseQueue;
  }

  transition(L2_IMOI, {L1_GETS, L1_GET_INSTR, L1_GETX}) {  // stall all L1 requests
    z_stall;
  }

  // transitions from L2_IMOZ
  // just wait for all acks and data
  // stall on all requests
  transition(L2_IMOZ, L2_INV) {  // could see an invalidate from the directory (earlier epoch)
    t_sendAckToInvalidator;
    l_popForwardedRequestQueue;
  }

  transition(L2_IMOZ, {Data_ext_ack_0, Data_ext_ack_not_0_last}, L2_MOZ) {
    u_writeDataFromResponseQueueToL2Cache;
    cc_issueStoreHitDG;
    ddd_setPendingIntAcksToOne;
    c_finalAckToDirIfNeeded;
    o_popIncomingResponseQueue;
  }

  transition(L2_IMOZ, Data_ext_ack_not_0) {
    u_writeDataFromResponseQueueToL2Cache;
    p_addNumberOfPendingExtAcks;
    mm_rememberIfFinalAckNeeded;
    o_popIncomingResponseQueue;
  }

  transition(L2_IMOZ, Proc_ext_ack) {
    q_decrementNumberOfPendingExtAcks;
    o_popIncomingResponseQueue;
  }

  transition(L2_IMOZ, Proc_last_ext_ack, L2_MOZ) {
    cc_issueStoreHitDG;
    ddd_setPendingIntAcksToOne;
    n_sendFinalAckIfThreeHop;
    o_popIncomingResponseQueue;
  }

  // stall on all requests
  transition(L2_IMOZ, {Forwarded_GETS, Forwarded_GET_INSTR, Forwarded_GETX, L1_GETS, L1_GET_INSTR, L1_GETX}) {
    z_stall;
  }

  // ===============================================
  // BASE STATE - S
  // Transitions from S, no L1 copies
  transition(L2_S, L2_Replacement, L2_I) {
    rr_deallocateL2CacheBlock;
  }

  transition(L2_S, L2_INV, L2_I) {  // could see an invalidate from the directory, but not Forwards
    t_sendAckToInvalidator;
    l_popForwardedRequestQueue;
  }

  transition(L2_S, {L1_GETS, L1_GET_INSTR}, L2_SS) {
    set_setMRU;
    ww_profileMissNoDir;
    nn_addSharer;
    k_dataFromL2CacheToL1Requestor;
    jj_popL1RequestQueue;
  }

  transition(L2_S, L1_GETX, L2_IM) {
    set_setMRU;
    nn_addSharer;
    i_allocateTBE;
    xx_recordGetXL1ID;
    b_issueGETX;
    uu_profileMiss;
    jj_popL1RequestQueue;
  }

  // BASE STATE - SS
  // Transitions from SS, L1 copies
  transition(L2_SS, L2_Replacement, L2_SIV) {
    i_allocateTBE;  // for internal request
    bbb_setPendingIntAcksToSharers;
    tt_issueSharedInvalidateIntL1copiesRequest;
  }

  transition(L2_SS, L2_INV, L2_SIC) {
    i_allocateTBE;  // for internal request
    yy_recordInvalidatorID;
    bbb_setPendingIntAcksToSharers;
    tt_issueSharedInvalidateIntL1copiesRequest;
    l_popForwardedRequestQueue;
  }

  transition(L2_SS, {L1_GETS, L1_GET_INSTR}) {
    set_setMRU;
    ww_profileMissNoDir;
    nn_addSharer;
    k_dataFromL2CacheToL1Requestor;
    jj_popL1RequestQueue;
  }

  transition(L2_SS, L1_UPGRADE_no_others, L2_IM) {
    set_setMRU;
    i_allocateTBE;  // for both ext. and int.
    xx_recordGetXL1ID;
    b_issueGETX;  // for external
    uu_profileMiss;
    jj_popL1RequestQueue;
  }

  transition(L2_SS, L1_UPGRADE, L2_IMV) {
    set_setMRU;
    i_allocateTBE;  // for both ext. and int.
    xx_recordGetXL1ID;
    ccc_setPendingIntAcksMinusOne;
    vv_issueInvalidateOtherIntL1copiesRequest;  // for internal
    b_issueGETX;  // for external
    uu_profileMiss;
    jj_popL1RequestQueue;
  }

  transition(L2_SS, L1_GETX, L2_IMV) {
    set_setMRU;
    i_allocateTBE;  // for both ext. and int.
    xx_recordGetXL1ID;
    bbb_setPendingIntAcksToSharers;
    vv_issueInvalidateOtherIntL1copiesRequest;  // for internal
    nn_addSharer;
    b_issueGETX;  // for external
    uu_profileMiss;
    jj_popL1RequestQueue;
  }

  transition(L2_SS, L1_PUTS) {
    ww_profileMissNoDir;
    w_sendPutAckToL1Cache;
    kk_removeRequestSharer;
    jj_popL1RequestQueue;
  }

  transition(L2_SS, L1_PUTS_last, L2_S) {
    ww_profileMissNoDir;
    w_sendPutAckToL1Cache;
    kk_removeRequestSharer;
    jj_popL1RequestQueue;
  }

  // Transitions from SIC - Initiated by an invalidate
  transition(L2_SIC, Proc_int_ack) {
    aa_removeResponseSharer;
    r_decrementNumberOfPendingIntAcks;
    o_popIncomingResponseQueue;
  }

  transition(L2_SIC, Proc_last_int_ack, L2_I) {
    aa_removeResponseSharer;
    r_decrementNumberOfPendingIntAcks;
    o_popIncomingResponseQueue;
    zz_sendAckToQueuedInvalidator;
    s_deallocateTBE;
  }

  transition(L2_SIC, L2_INV) {  // could see an invalidate from the directory, but not Forwards
    l_popForwardedRequestQueue;  // ignore: already know an ack must be sent to the directory
  }

  transition(L2_SIC, {L1_GETS, L1_GET_INSTR, L1_UPGRADE, L1_UPGRADE_no_others, L1_GETX}) {   // stall on all L1 requests
    z_stall;
  }

  // Transitions from SIV - initiated by a L2_Replacement
  transition(L2_SIV, Proc_int_ack) {
    aa_removeResponseSharer;
    r_decrementNumberOfPendingIntAcks;
    o_popIncomingResponseQueue;
  }

  transition(L2_SIV, Proc_last_int_ack, L2_I) {
    aa_removeResponseSharer;
    r_decrementNumberOfPendingIntAcks;
    o_popIncomingResponseQueue;
    s_deallocateTBE;
    rr_deallocateL2CacheBlock;
  }

  transition(L2_SIV, L2_INV) {  // could see an invalidate from the directory, but not Forwards
    z_stall;  // guarenteed to receive all acks thus moving the state to I where the L2_INV can be handled
  }

  transition(L2_SIV, {L1_GETS, L1_GET_INSTR, L1_UPGRADE, L1_UPGRADE_no_others, L1_GETX}) {   // stall on all L1 requests
    z_stall;
  }

  // ===============================================
  // BASE STATE - M
  // Transitions from M, no L1 copies
  transition(L2_M, L2_Replacement, L2_MIN) {
    i_allocateTBE;
    d_issuePUTX;
    x_copyDataFromL2CacheToTBE;
    rr_deallocateL2CacheBlock;
  }

  transition(L2_M, {Forwarded_GETS,Forwarded_GET_INSTR}, L2_O) {  // can see forwards, not inv
    e_dataFromL2CacheToL2Requestor;
    l_popForwardedRequestQueue;
  }

  transition(L2_M, Forwarded_GETX, L2_I) {  // can see forwards, not inv
    e_dataFromL2CacheToL2Requestor;
    l_popForwardedRequestQueue;
  }

  transition(L2_M, {L1_GETS, L1_GET_INSTR}, L2_SO) {  // FIXME FOR BETTER PERFORMANCE - an E state would be nice here
    set_setMRU;
    ww_profileMissNoDir;
    nn_addSharer;
    k_dataFromL2CacheToL1Requestor;
    jj_popL1RequestQueue;
  }

  transition(L2_M, L1_GETX, L2_MT) {
    set_setMRU;
    ww_profileMissNoDir;
    nn_addSharer;
    k_dataFromL2CacheToL1Requestor;
    jj_popL1RequestQueue;
  }

  // BASE STATE - MT
  // Transitions from MT, M L1 copy
  transition(L2_MT, L2_Replacement, L2_MIV) {
    i_allocateTBE;
    bbb_setPendingIntAcksToSharers;
    v_issueInvalidateIntL1copyRequest;
  }

  transition(L2_MT, {Forwarded_GETS, Forwarded_GET_INSTR}, L2_MO) {  // can see forwards, not inv
    i_allocateTBE;
    bbb_setPendingIntAcksToSharers;
    g_issueDownGradeIntL1copiesRequest;
    dd_recordGetSForwardID;
    l_popForwardedRequestQueue;
  }

  transition(L2_MT, {L1_GETS, L1_GET_INSTR}, L2_MO) {
    set_setMRU;
    ww_profileMissNoDir;
    i_allocateTBE;
    bbb_setPendingIntAcksToSharers;
    g_issueDownGradeIntL1copiesRequest;
    ss_recordGetSL1ID;
    nn_addSharer;
    jj_popL1RequestQueue;
  }

  transition(L2_MT, Forwarded_GETX, L2_MIC) {  // can see forwards, not inv
    i_allocateTBE;
    bbb_setPendingIntAcksToSharers;
    v_issueInvalidateIntL1copyRequest;
    ii_recordGetXForwardID;
    l_popForwardedRequestQueue;
  }

  transition(L2_MT, L1_GETX, L2_MIT) {
    set_setMRU;
    ww_profileMissNoDir;
    i_allocateTBE;
    bbb_setPendingIntAcksToSharers;
    v_issueInvalidateIntL1copyRequest;
    nn_addSharer;
    xx_recordGetXL1ID;
    jj_popL1RequestQueue;
  }

  transition(L2_MT, L1_PUTX_last, L2_M) {
    ww_profileMissNoDir;
    w_sendPutAckToL1Cache;
    kk_removeRequestSharer;
    m_writeDataFromRequestQueueToL2Cache;
    jj_popL1RequestQueue;
  }

  // Transitions from L2_MIV, waiting for local L1 response
  transition(L2_MIV, Data_int_ack, L2_MIN) {
    aa_removeResponseSharer;
    u_writeDataFromResponseQueueToL2Cache;
    bb_dataFromL2CacheToGetSForwardIDs;  // likely won't send any messages
    gg_dataFromL2CacheToGetXForwardID;  // likely won't send any messages
    d_issuePUTX;
    x_copyDataFromL2CacheToTBE;
    rr_deallocateL2CacheBlock;
    o_popIncomingResponseQueue;
  }

  transition(L2_MIV, {Forwarded_GETS,Forwarded_GET_INSTR}) {  // could see Forwards
    dd_recordGetSForwardID;
    l_popForwardedRequestQueue;
  }

  transition(L2_MIV, Forwarded_GETX) {  // could see Forwards
    ii_recordGetXForwardID;
    l_popForwardedRequestQueue;
  }

  transition(L2_MIV, {L1_GETS, L1_GET_INSTR, L1_GETX}) {   // stall on all L1 requests
    z_stall;
  }

  // Transitions from L2_MIN, waiting for directory ack
  transition(L2_MIN, {Forwarded_GETS,Forwarded_GET_INSTR}) {  // could see Forwards
    y_dataFromTBEToRequestor;
    l_popForwardedRequestQueue;
  }

  transition(L2_MIN, Forwarded_GETX) {  // could see Forwards
    y_dataFromTBEToRequestor;
    l_popForwardedRequestQueue;
  }

  transition(L2_MIN, Dir_WB_ack, L2_I) {
    s_deallocateTBE;
    l_popForwardedRequestQueue;
  }

  transition(L2_MIN, {L1_GETS, L1_GET_INSTR, L1_GETX}) {  // stall all L1 requests
    z_stall;
  }

  // Transitions from L2_MIC, waiting for local L1 response
  // Directory put us in this state with a forwarded GetX
  // therefore we shouldn't see anymore forwards
  // we stall on all L1 requests
  transition(L2_MIC, Data_int_ack, L2_I) {
    aa_removeResponseSharer;
    u_writeDataFromResponseQueueToL2Cache;
    gg_dataFromL2CacheToGetXForwardID;
    s_deallocateTBE;
    o_popIncomingResponseQueue;
  }
  
  transition(L2_MIC, {L1_GETS, L1_GET_INSTR, L1_GETX}) {  // stall all L1 requests
    z_stall;
  }

  // Transitions from L2_MIT, waiting for local L1 response
  // A local L1 request put us in this state, so any request are possible
  // we currently stall all requests because of the ugly recursive path it could lead us on
  // removing some of the blocking here could have major performance benefits
  // however one must be careful not to violate cache coherence
  transition(L2_MIT, Data_int_ack, L2_MT) {
    aa_removeResponseSharer;
    u_writeDataFromResponseQueueToL2Cache;
    hh_issueStoreHit;  // internal requestor
    s_deallocateTBE;
    o_popIncomingResponseQueue;
  }

  // stall all requests
  transition(L2_MIT, {Forwarded_GETS, Forwarded_GET_INSTR, Forwarded_GETX, L1_GETS, L1_GET_INSTR, L1_GETX}) {
    z_stall;
  }

  // Transistion from L2_MO, waiting for local L1 data response
  // a GetS request put us in this state
  // stall must stall if we get a GETX request
  transition(L2_MO, Data_int_ack, L2_SO) {
    u_writeDataFromResponseQueueToL2Cache;
    ee_dataFromL2CacheToGetSIDs;  // could be an internal or external requestor
    s_deallocateTBE;
    o_popIncomingResponseQueue;
  }  

  transition(L2_MO, {Forwarded_GETS, Forwarded_GET_INSTR}) {  // can see forwards, not inv
    dd_recordGetSForwardID;
    l_popForwardedRequestQueue;
  }

  transition(L2_MO, {L1_GETS, L1_GET_INSTR}) {
    set_setMRU;
    ww_profileMissNoDir;
    nn_addSharer;
    ss_recordGetSL1ID;
    jj_popL1RequestQueue;
  }

  transition(L2_MO, Forwarded_GETX, L2_MOIC) {  // can see forwards, not inv
    ii_recordGetXForwardID;
    l_popForwardedRequestQueue;
  }

  transition(L2_MO, {L1_GETX, L1_UPGRADE, L1_UPGRADE_no_others}, L2_MOZ) {  // don't go there, just go to a stall state
    z_stall;
  }

  // Transistion from L2_MOIC
  // a Forwarded_GETX put us here so we should not see any more forwards
  // stall on all L1 requests, once data is received send new data to all queued up L1 shares
  // then immediately send invalidate request to those new L1 shared copies
  // 
  // KEY DIFFERENCE: L2_MOICR assumes the L1 data responder moved to I state and removes the sharer,
  // while L2_MOIC assumes the L1 data responder moved to S state and doesn't remove the sharer
  transition(L2_MOIC, Data_int_ack, L2_OIC) { // need only one ack
    u_writeDataFromResponseQueueToL2Cache;
    ee_dataFromL2CacheToGetSIDs;
    bbb_setPendingIntAcksToSharers;
    tt_issueSharedInvalidateIntL1copiesRequest; 
    o_popIncomingResponseQueue;
  }  

  transition(L2_MOIC, {L1_GETS, L1_GET_INSTR, L1_GETX, L1_UPGRADE, L1_UPGRADE_no_others}) {
    z_stall;
  }

  // Transistion from L2_MOICR
  // a Forwarded_GETX put us here so we should not see any more forwards
  // stall on all L1 requests, once data is received send new data to all queued up L1 shares
  // then immediately send invalidate request to those new L1 shared copies
  // 
  // KEY DIFFERENCE: L2_MOICR assumes the L1 data responder moved to I state and removes the sharer,
  // while L2_MOIC assumes the L1 data responder moved to S state and doesn't remove the sharer
  transition(L2_MOICR, Data_int_ack, L2_OIC) { // need only one ack
    aa_removeResponseSharer;
    u_writeDataFromResponseQueueToL2Cache;
    ee_dataFromL2CacheToGetSIDs;
    bbb_setPendingIntAcksToSharers;
    tt_issueSharedInvalidateIntL1copiesRequest; 
    o_popIncomingResponseQueue;
  }  

  transition(L2_MOICR, {L1_GETS, L1_GET_INSTR, L1_GETX}) {
    z_stall;
  }

  // L2_MOZ
  // simply wait on data
  // stall on everything
  transition(L2_MOZ, Data_int_ack, L2_SO) {
    u_writeDataFromResponseQueueToL2Cache;
    ee_dataFromL2CacheToGetSIDs;  // could be an internal or external requestor
    s_deallocateTBE;
    o_popIncomingResponseQueue;
  }  
  
  // stall everything
  transition(L2_MOZ, {Forwarded_GETS, Forwarded_GET_INSTR, Forwarded_GETX, L1_GETS, L1_GET_INSTR, L1_GETX, L1_UPGRADE, L1_UPGRADE_no_others}) {
    z_stall;
  }

  // ===============================================
  // BASE STATE - O
  // Transitions from L2_O, only block cached on the chip
  transition(L2_O, L2_Replacement, L2_OIN){
    i_allocateTBE;
    x_copyDataFromL2CacheToTBE;
    d_issuePUTX;
    rr_deallocateL2CacheBlock;
  }

  transition(L2_O, {Forwarded_GETS,Forwarded_GET_INSTR}) {
    e_dataFromL2CacheToL2Requestor;  
    l_popForwardedRequestQueue;
  }

  transition(L2_O, Forwarded_GETX, L2_I) {
    e_dataFromL2CacheToL2Requestor;  
    l_popForwardedRequestQueue;
  }

  transition(L2_O, {L1_GETS, L1_GET_INSTR}, L2_SO) {
    set_setMRU;
    ww_profileMissNoDir;
    nn_addSharer;
    k_dataFromL2CacheToL1Requestor;
    jj_popL1RequestQueue;
  }

  transition(L2_O, L1_GETX, L2_OM) {
    set_setMRU;
    nn_addSharer;
    i_allocateTBE;
    xx_recordGetXL1ID;
    b_issueGETX;
    uu_profileMiss;
    jj_popL1RequestQueue;
  }

  // BASE STATE - SO
  // Transitions from L2_SO, other valid L1 cached copies
  transition(L2_SO, L2_Replacement, L2_OIV){
    i_allocateTBE;
    x_copyDataFromL2CacheToTBE;
    bbb_setPendingIntAcksToSharers;
    tt_issueSharedInvalidateIntL1copiesRequest;
  }

  transition(L2_SO, {Forwarded_GETS,Forwarded_GET_INSTR}) {
    e_dataFromL2CacheToL2Requestor;  
    l_popForwardedRequestQueue;
  }

  transition(L2_SO, Forwarded_GETX, L2_OIC) {
    i_allocateTBE;
    bbb_setPendingIntAcksToSharers;
    ii_recordGetXForwardID;
    tt_issueSharedInvalidateIntL1copiesRequest;
    l_popForwardedRequestQueue;
  }

  transition(L2_SO, {L1_GETS, L1_GET_INSTR}) {
    set_setMRU;
    ww_profileMissNoDir;
    nn_addSharer;
    k_dataFromL2CacheToL1Requestor;
    jj_popL1RequestQueue;
  }

  transition(L2_SO, L1_UPGRADE, L2_OMV) {
    set_setMRU;
    nn_addSharer;
    i_allocateTBE;
    xx_recordGetXL1ID;
    ccc_setPendingIntAcksMinusOne;
    vv_issueInvalidateOtherIntL1copiesRequest;  // for internal
    b_issueGETX;  // for external
    uu_profileMiss;
    jj_popL1RequestQueue;
  }

  transition(L2_SO, L1_UPGRADE_no_others, L2_OM) {
    set_setMRU;
    i_allocateTBE;
    xx_recordGetXL1ID;
    b_issueGETX;  // for external
    uu_profileMiss;
    jj_popL1RequestQueue;
  }

  transition(L2_SO, L1_GETX, L2_OMV) {
    set_setMRU;
    i_allocateTBE;
    xx_recordGetXL1ID;
    bbb_setPendingIntAcksToSharers;
    vv_issueInvalidateOtherIntL1copiesRequest;
    nn_addSharer;
    b_issueGETX;  // for external
    uu_profileMiss;
    jj_popL1RequestQueue;
  }

  transition(L2_SO, {L1_PUTS, L1_PUTX}) {  // PUTX possible because L2 downgraded before seeing PUTX
    ww_profileMissNoDir;
    w_sendPutAckToL1Cache;
    kk_removeRequestSharer;
    jj_popL1RequestQueue;
  }

  transition(L2_SO, {L1_PUTS_last, L1_PUTX_last}, L2_O) { // PUTX possible because L2 downgraded before seeing PUTX
    ww_profileMissNoDir;
    w_sendPutAckToL1Cache;
    kk_removeRequestSharer;
    jj_popL1RequestQueue;
  }

  // Transitions from L2_OIV
  // L2 replacement put us here, we must stall all L1 requests
  transition(L2_OIV, {Forwarded_GETS, Forwarded_GET_INSTR}) {
    y_dataFromTBEToRequestor;
    l_popForwardedRequestQueue;
  }

  transition(L2_OIV, Forwarded_GETX) {
    z_stall;
  }

  transition(L2_OIV, Proc_int_ack) {
    aa_removeResponseSharer;
    r_decrementNumberOfPendingIntAcks
    o_popIncomingResponseQueue;
  }

  transition(L2_OIV, Proc_last_int_ack, L2_OIN) {
    aa_removeResponseSharer;
    r_decrementNumberOfPendingIntAcks
    o_popIncomingResponseQueue;
    d_issuePUTX;
    rr_deallocateL2CacheBlock;
  }

  transition(L2_OIV, {L1_UPGRADE, L1_UPGRADE_no_others, L1_GETX, L1_GETS, L1_GET_INSTR}) {  // stall L1 requests
    z_stall;
  }

  // transitions from L2_OIN
  // L2 replacement put us here, we must stall all L1 requests
  transition(L2_OIN, {Forwarded_GETS, Forwarded_GET_INSTR, Forwarded_GETX}) {
    y_dataFromTBEToRequestor;
    l_popForwardedRequestQueue;
  }

  transition(L2_OIN, Dir_WB_ack, L2_I) {
    s_deallocateTBE;
    l_popForwardedRequestQueue;
  }

  transition(L2_OIN, {L1_UPGRADE, L1_UPGRADE_no_others, L1_GETX, L1_GETS, L1_GET_INSTR}) {  // stall L1 requests
    z_stall;
  }

  // transitions from L2_OIC
  // directory put us in this state, should not see any forwards
  // we must stall all L1 requests
  transition(L2_OIC, Proc_int_ack) {
    aa_removeResponseSharer;
    r_decrementNumberOfPendingIntAcks
    o_popIncomingResponseQueue;
  }

  transition(L2_OIC, Proc_last_int_ack, L2_I) {
    aa_removeResponseSharer;
    r_decrementNumberOfPendingIntAcks
    gg_dataFromL2CacheToGetXForwardID;
    s_deallocateTBE;
    o_popIncomingResponseQueue;
  }

  transition(L2_OIC, {L1_UPGRADE, L1_UPGRADE_no_others, L1_GETX, L1_GETS, L1_GET_INSTR}) {  // stall L1 requests
    z_stall;
  }

  // Transitions from L2_OMV, 
  // int_acks needed
  // waiting to see our Forwarded GETX from the directory
  // if we see the Forwarded GETX before all invalidates received, stall
  // stall all L1 requests
  transition(L2_OMV, Proc_int_ack) {
    aa_removeResponseSharer;
    r_decrementNumberOfPendingIntAcks;
    o_popIncomingResponseQueue;
  }

  transition(L2_OMV, Proc_last_int_ack, L2_OM) {
    aa_removeResponseSharer;
    r_decrementNumberOfPendingIntAcks;
    o_popIncomingResponseQueue;
  }

  transition(L2_OMV, Proc_ext_ack) {
    q_decrementNumberOfPendingExtAcks;
    o_popIncomingResponseQueue;
  }

  transition(L2_OMV, {Forwarded_GETS, Forwarded_GET_INSTR}) {  // these are GetS that beat us to the directory
    e_dataFromL2CacheToL2Requestor;  
    l_popForwardedRequestQueue;
  }

  transition(L2_OMV, Dir_exe_ack, L2_MV) {
    l_popForwardedRequestQueue;
  }

  transition(L2_OMV, Forwarded_GETX) {  // the Forwarded GetX may or may not be ours, we can't respond until int_acks received
    z_stall;
  }

  transition(L2_OMV, {L1_UPGRADE, L1_UPGRADE_no_others, L1_GETS, L1_GET_INSTR, L1_GETX}) {  // must stall all L1 requests
    z_stall;
  }

  // Transitions from L2_OM, 
  // all L1 copies invalid, no int_acks needed
  // waiting to see our Forwarded GETX from the directory
  // once we see the Forwarded GETX, we can move to IM and wait for the data_ack
  // stall all L1 requests
  transition(L2_OM, Proc_ext_ack) {
    q_decrementNumberOfPendingExtAcks;
    o_popIncomingResponseQueue;
  }

  transition(L2_OM, {Forwarded_GETS, Forwarded_GET_INSTR}) {  // these are GetS that beat us to the directory
    e_dataFromL2CacheToL2Requestor;  
    l_popForwardedRequestQueue;
  }

  transition(L2_OM, Forwarded_GETX, L2_IM) {  // the Forwarded GetX may or may not be ours
    e_dataFromL2CacheToL2Requestor;  // we're probably sending a message to ourselves here, but not guarenteed
    l_popForwardedRequestQueue;
  }

  transition(L2_OM, Dir_exe_ack, L2_MT) {  // Directory tells us we already have an exclusive copy
    hh_issueStoreHit;
    s_deallocateTBE;
    l_popForwardedRequestQueue;
  }

  transition(L2_OM, {L1_UPGRADE, L1_UPGRADE_no_others, L1_GETS, L1_GET_INSTR, L1_GETX}) {  // must stall all L1 requests
    z_stall;
  }

}
